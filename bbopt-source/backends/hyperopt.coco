"""
The hyperopt backend. Does black box optimization using hyperopt.
"""

import numpy as np

from hyperopt import (
    hp,
    tpe,
    FMinIter,
    anneal,
)
from hyperopt.pyll import as_apply
from hyperopt.base import (
    Domain,
    Trials,
    STATUS_OK,
    STATUS_RUNNING,
    JOB_STATE_DONE,
    spec_from_misc,
)

from bbopt.util import sorted_items
from bbopt.backends.util import (
    Backend,
    negate_objective,
    make_features,
)


# Utilities:

def create_space(name, func, *args):
    """Create a hyperopt space for the given param kwargs."""
    case func:
        match "choice":
            return hp.choice(name, *args)
        match "randrange":
            start, stop, step = args
            if step != 1:
                raise ValueError("the hyperopt backend only supports a randrange step size of 1")
            # despite being called randint, hp.randint is exclusive
            return start + hp.randint(name, stop - start)
        match "uniform":
            return hp.uniform(name, *args)
        match "normalvariate":
            return hp.normal(name, *args)
    raise TypeError(f"insufficiently specified parameter {name}")


def examples_to_trials(examples, params):
    """Create hyperopt trials from the given examples."""
    trials = []
    NA = object()  # used to mark missing values

    for tid, ex in enumerate(examples):

        match {"gain": gain, **_} in ex:
            loss = negate_objective(gain)
        else:
            loss = ex["loss"]
        result = {
            "status": STATUS_OK,
            "loss": loss,
        }

        vals = {}
        idxs = {}
        for k, v in zip(
            sorted(params),
            make_features(
                ex["values"],
                params,
                fallback_func=(name, func, *args, **kwargs) -> NA,
                converters={
                    "choice": (val, choices) -> choices.index(val),
                    "randrange": (val, start, stop, step) -> val - start,
                },
                convert_fallback=False,
            ),
        ):
            vals[k] = [v] if v is not NA else []
            idxs[k] = [tid] if v is not NA else []

        misc = {
            "tid": tid,
            "idxs": idxs,
            "vals": vals,
            "cmd": None,
        }

        trials.append({
            "tid": tid,
            "result": result,
            "misc": misc,
            "spec": spec_from_misc(misc),
            "state": JOB_STATE_DONE,
            "owner": None,
            "book_time": None,
            "refresh_time": None,
            "exp_key": None,
        })

    return trials


# Backend:

class HyperoptBackend(Backend):
    """The hyperopt backend uses hyperopt for black box optimization."""
    backend_name = "hyperopt"
    implemented_funcs = (
        # should match create_space above
        "choice",
        "randrange",
        "uniform",
        "normalvariate",
    )

    def __init__(self, examples, params, algo=tpe.suggest, rstate=np.random.RandomState(), show_progressbar=False, **options):
        self.init_fallback_backend()

        if not examples:
            self.current_values = {}
            return

        space = {
            name: create_space(name, func, *args)
            for name, (func, args, kwargs) in sorted_items(params)
        } |> as_apply

        domain = Domain(self.set_current_values, space)

        trial_list = examples_to_trials(examples, params)

        trials = Trials()
        trials.insert_trial_docs(trial_list)

        # run one iteration of hyperparameter optimization, with values saved
        #  to the self.set_current_values callback passed to Domain
        FMinIter(
            algo,
            domain,
            trials,
            rstate,
            show_progressbar=show_progressbar,
            **options,
        ) |> next

        assert self.current_values is not None, self.current_values
        assert set(self.current_values.keys()) == set(params), self.current_values

    def set_current_values(self, values):
        """Callback to set the values for this run."""
        assert isinstance(values, dict), values
        self.current_values = values
        return {
            "status": STATUS_RUNNING,
        }


# Registered names:

HyperoptBackend.register()
HyperoptBackend.register_alg("tree_structured_parzen_estimator")
HyperoptBackend.register_alg("annealing", algo=anneal.suggest)
